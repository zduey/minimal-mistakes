---
title: Critical Thinking, Bayesian Statistics, and Effective Political Discourse -- Part 1

categories:
    - miscellaneous
tags:
    - bayesian
    - personal
---

Over the next several weeks, I will be releasing a series of posts that discusses hyperpartisanship in the United States through an extended analogy between Bayesian statistics and critical thinking. I should start with a few disclaimers:

1. I fully recognize the set of people who will be interested in this post is likely to be very small. Thanks in advance if you make it through to the end.
2. I am not an expert in political science or Bayesian statistics, so please correct me in places where I am blatantly or subtely wrong in my statements
3. I am sure that the connection between Bayesian statistics and opinion formation has been discussed before. I have intentionally not researched the topic so that these thoughts are as clos to my own as possible
4. These posts are in draft state, so any constructive feedback is much appreciated


# Part 1 -- The Set Up

There is a problem with the state of political discourse in the United States. While *intra*-party discourse can and should be improved, what has me more concerned, what keeps me awake at night, and what should trouble all of us is how the current level of hyperpartisanship has all but destroyed *inter*-party discourse. While I recognize that there are many issues facing our nation and world today -- from climate change, to the potential for nuclear war -- it is hyperpartisanship that keeps me awake at night  because I cannot see how it is possible to solve any of these pressing issues without first solving the problem of our inability to communicate effectively with one another. From the family dinner table to Washington, productive political dialogue is rare, basic factual statements are not readily and unequivocally recognized as such, and even in the face of compelling evidence we are generally unwilling to change our minds. While there is room for debate about the severity and scope of the issue, my hope is that we can collectively recognize that hyperpartisanship is a problem on some level and begin to collectively address how it can be fixed so that we can solve these other critical problems.

I stress the collective aspect because I believe that the problem neither originated with any particular political group nor can it be solved by any single group. Instead, I contend that hyperpartisanship is a rational outgrowth of the information overload we experience as being part of the modern world: a world defined by nearly instantaneous communication, an endless barrage of information, and perilous variety in the quality of information. At its core, I think the solution is to deliberately emphasize quality over quantity (or expediency) in the information that we choose to consume on a daily basis. We need to reduce the noise we expose ourselves to and take intentional steps towards becoming more effective critical thinkers. However, “critical thinking” is one of those nebulous terms that gets thrown around without much care, so, perhaps a better way to arrive at the how part of the solution is by finding a model to follow. The big surprise is that this model is not a *who*, but rather a *what*. 

In order to become better critical thinkers, make strides towards more effective political discourse, and ultimately make better policy decisions, I think we need to give some serious consideration to what we can learn about the relationship between information and learning from Bayesian statistics. Let me clarify that my point is not that we can solve all of our political problems with statistics. While there is a role for statistical analysis to play in informing policy decisions, we can leave that to the economists, statisticians, criminologist, and other social scientists that contribute to these efforts. Instead, what I am imagining takes a more abstract, perhaps philosophical, view of how Bayesian statistics can serve as a model for opinion formation. 

At its core, a Bayesian approach involves codifying beliefs and then systematically using new information to update those beliefs. Put in an opinion-formation context, this process would mean that after consuming any piece of information, a person’s opinion is a statement about the world that is neither black nor white, is informed by relevant information, and was reached through a rational and systematic process. To some quantitative types this may seem totally rational and reasonable, but perhaps to others, it sounds like I am arguing that humans would be better off operating as information-processing automata (perhaps some other already think that is exactly what humans are). Let me be clear that I am not making the normative claim that we all should process information in this calculated, deterministic way. In fact, I do not think we could operate in this way if we wanted to. Instead, my point is that I think there is value in understanding how such a process works when thinking about how to solve the problem of hyperpartisanship. However, like any analogy, the devil is in the details, which we will get in to in the next post.
